{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6099b107",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114d92b7",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/responsible-ai/model-analysis/regression/azureml-model-analysis-regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45715712",
   "metadata": {},
   "source": [
    "# Model analysis for regression scenarios\n",
    "**This notebook will demonstrate on how to compute Responsible AI insights like explanations, counterfactual examples, causal effects and error analysis on remote compute for a regression model.**\n",
    "\n",
    "## Contents\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "1. [Dataset](#Dataset)\n",
    "1. [Create or attach existing AmlCompute cluster](#AmlCompute)\n",
    "1. [Train model on remote compute](#Train)\n",
    "1. [Generate RAI insights](#Generate)\n",
    "1. [Responsible AI dashboard](#Dashboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968262e",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "## Install azureml-responsible-ai \n",
    "`pip install azureml-responsibleai` before running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b34ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azureml-responsibleai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "from azureml.core import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "from responsibleai import ModelAnalysis\n",
    "from azureml.responsibleai.common.pickle_model_loader import PickleModelLoader\n",
    "from azureml.responsibleai.tools.model_analysis.model_analysis_config import ModelAnalysisConfig\n",
    "from azureml.responsibleai.tools.model_analysis.model_analysis_run import ModelAnalysisRun\n",
    "from azureml.responsibleai.tools.model_analysis.explain_config import ExplainConfig\n",
    "from azureml.responsibleai.tools.model_analysis.causal_config import CausalConfig\n",
    "from azureml.responsibleai.tools.model_analysis.counterfactual_config import CounterfactualConfig\n",
    "from azureml.responsibleai.tools.model_analysis.error_analysis_config import ErrorAnalysisConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dc6ff4",
   "metadata": {},
   "source": [
    "## Link an AzureML workspace\n",
    "\n",
    "To use this notebook, an Azure Machine Learning workspace is required.\n",
    "Please see the [configuration notebook](../../configuration.ipynb) for information about creating one, if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43713044",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_workspace = Workspace.from_config()\n",
    "print('Workspace name: ' + user_workspace.name, \n",
    "      'Azure region: ' + user_workspace.location, \n",
    "      'Subscription id: ' + user_workspace.subscription_id, \n",
    "      'Resource group: ' + user_workspace.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9345df96",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "This notebook uses the Boston housing dataset. Below we load the Boston Hosuing dataset and split the dataset into train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb3d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = sklearn.datasets.load_boston()\n",
    "target_feature = 'y'\n",
    "continuous_features = data.feature_names\n",
    "data_df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_df, data.target, test_size=0.2, random_state=7)\n",
    "\n",
    "train_data = X_train.copy()\n",
    "test_data = X_test.copy()\n",
    "train_data[target_feature] = y_train\n",
    "test_data[target_feature] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b63b8a",
   "metadata": {},
   "source": [
    "## Upload the train and test dataset to datastore\n",
    "In the cell below, we upload the train and test datasets to the default datastore and register the train data and test data as azureml datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "datastore = user_workspace.get_default_datastore()\n",
    "\n",
    "# Upload train data to datastore\n",
    "train_name = 'boston_train'\n",
    "train_datastore_path = (datastore, train_name)\n",
    "train_dataset = Dataset.Tabular.register_pandas_dataframe(\n",
    "    train_data, train_datastore_path, train_name)\n",
    "\n",
    "\n",
    "# Upload test data to datastore\n",
    "test_name = 'boston_test'\n",
    "test_datastore_path = (datastore, test_name)\n",
    "test_dataset = Dataset.Tabular.register_pandas_dataframe(\n",
    "    test_data, test_datastore_path, test_name)\n",
    "\n",
    "label = 'y'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3f990",
   "metadata": {},
   "source": [
    "## Identify continous and categorical features\n",
    "Below we identify continous and categorical features in the above dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1f8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_features = X_train.columns\n",
    "categorical_features = []\n",
    "feature_names = X_train.columns\n",
    "continuous_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3971a",
   "metadata": {},
   "source": [
    "# Create or attach existing AmlCompute cluster\n",
    "\n",
    "You will need to create a [compute target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) for training your model and computing RAI insights for the trained model. In this tutorial, you create `AmlCompute` as your training compute resource.\n",
    "\n",
    "> Note that if you have an AzureML Data Scientist role, you will not have permission to create compute resources. Talk to your workspace or IT admin to create the compute targets described in this section, if they do not already exist.\n",
    "\n",
    "**Creation of AmlCompute takes approximately 5 minutes.** If the AmlCompute with that name is already in your workspace this code will skip the creation process.\n",
    "\n",
    "As with other Azure services, there are limits on certain resources (e.g. AmlCompute) associated with the Azure Machine Learning service. Please read [this article](https://docs.microsoft.com/en-us/azure/machine-learning/service/how-to-manage-quotas) on the default limits and how to request more quota.# Create cimpute cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cpu_cluster_name = \"rai-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=user_workspace, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS12_V2',\n",
    "                                                           max_nodes=6)\n",
    "    compute_target = ComputeTarget.create(user_workspace, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9fe2b",
   "metadata": {},
   "source": [
    "# Train model on remote compute\n",
    "In this section, we train a simple regression model on the remote compute.\n",
    "\n",
    "Add `azureml-responsibleai` as a pip dependency in the run configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb743cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config = RunConfiguration(framework=\"python\")\n",
    "conda_dependencies = CondaDependencies.create()\n",
    "run_config.environment.python.conda_dependencies = conda_dependencies\n",
    "run_config.environment.python.conda_dependencies.add_pip_package(\"azureml-responsibleai=={}\".format(azureml.core.VERSION))\n",
    "run_config.target = compute_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949dd538",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aabac21",
   "metadata": {},
   "source": [
    "Copy the train script into the script directory. This train script will be used to train the model and register the model on remote compute.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a4f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# create script folder\n",
    "script_folder = './sample_projects/regression-boston'\n",
    "if not os.path.exists(script_folder):\n",
    "    os.makedirs(script_folder)\n",
    "\n",
    "# Copy the sample script to script folder.\n",
    "shutil.copy('train.py', script_folder)\n",
    "\n",
    "# Create the explainer script that will run on the remote compute.\n",
    "script_file_name = script_folder + '/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ada22f",
   "metadata": {},
   "source": [
    "Submit the train script via `ScriptRunConfig` to train the model on remote compute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec21f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now submit a run on AmlCompute for model explanations\n",
    "from azureml.core.script_run_config import ScriptRunConfig\n",
    "\n",
    "exp_name = \"RAI-Regression-Boston\"\n",
    "experiment = Experiment(user_workspace, exp_name)\n",
    "\n",
    "\n",
    "script_run_config = ScriptRunConfig(source_directory=script_folder,\n",
    "                                    script='train.py',\n",
    "                                    run_config=run_config)\n",
    "\n",
    "run = experiment.submit(script_run_config)\n",
    "\n",
    "# Show run details\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145df4e",
   "metadata": {},
   "source": [
    "Wait for the above model training run to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91655762",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(raise_on_error=True, wait_post_processing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3330c4be",
   "metadata": {},
   "source": [
    "# Generate RAI insights\n",
    "\n",
    "This section will walk you through the workflow to compute Responsible AI insights like model explanations, counterfactual examples, causal effects and error analysis using model analysis workflow on your remote compute for the model trained in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b961c9c9",
   "metadata": {},
   "source": [
    "## Configure model analysis and submit RAI insight computation runs\n",
    "In this section, we will demonstrate how to configure model analysis, submit the model analysis run and submit the individual RAI computations for explanations, counterfactual examples, error analysis and causal effects for your trained model\n",
    "\n",
    "\n",
    "### Create ModelAnalysis configuration\n",
    "\n",
    "Create `ModelAnalysisConfig` for computing the RAI insights for the trained model. The `ModelAnalysisConfig` requires the following:-\n",
    "1. The registered model which was registered during the model training.\n",
    "2. The train and test datasets.\n",
    "3. `confidential_datastore_name`which is the name of the datastore where the analyses will be uploaded.\n",
    "4. List of the feature column names by dropping the name of the label column from the list of all column names.\n",
    "5. List of categorical features.\n",
    "6. Azureml run configuration whcih was setup in the previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a8467",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model = Model.list(user_workspace, 'boston')[0]\n",
    "model_loader = PickleModelLoader('boston.pkl')\n",
    "\n",
    "train_dataset = Dataset.get_by_name(workspace=user_workspace, name='boston_train')\n",
    "test_dataset = Dataset.get_by_name(workspace=user_workspace, name='boston_test')\n",
    "\n",
    "ma = ModelAnalysisConfig(\n",
    "    title=\"RAI Regression Boston\",\n",
    "    model=registered_model,\n",
    "    model_type='regression',\n",
    "    model_loader=model_loader,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset,\n",
    "    X_column_names=feature_names,\n",
    "    target_column_name=label,\n",
    "    confidential_datastore_name=user_workspace.get_default_datastore().name,\n",
    "    run_configuration=run_config,\n",
    "    categorical_column_names=categorical_features\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef15c7fa",
   "metadata": {},
   "source": [
    "### Submit Model Analysis run\n",
    "\n",
    "The model analysis run takes a snapshot of the data in preparation for model explanation, error analysis, causal and counterfactual.\n",
    "The model analysis run is the parent run for the model explanation, error analysis, causal and counterfactual runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab78f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(user_workspace, exp_name)\n",
    "\n",
    "model_analysis_run = experiment.submit(ma)\n",
    "model_analysis_run.wait_for_completion(raise_on_error=True,\n",
    "                                       wait_post_processing=True)\n",
    "model_analysis_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ae01",
   "metadata": {},
   "source": [
    "### Submit run for explanations\n",
    "\n",
    "Run model explanation based on the model analysis.\n",
    "The explanation run is a child run of the model analysis run.\n",
    "In the future, the `add_request` method will allow extra parameters to configure the explanation generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ExplainConfig(model_analysis_run, run_config)\n",
    "ec.add_request(\"Compute Explanations\")\n",
    "explain_run = model_analysis_run.submit_child(ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385688d4",
   "metadata": {},
   "source": [
    "### Submit run for error analysis\n",
    "\n",
    "Run error analysis based on the model analysis.\n",
    "The error analysis run is a child run of the model analysis run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b714c7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = ErrorAnalysisConfig(model_analysis_run, run_config)\n",
    "ec.add_request(max_depth=3, comment=\"Compute ErrorAnalysis\")\n",
    "error_analysis_run = model_analysis_run.submit_child(ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5f4aea",
   "metadata": {},
   "source": [
    "### Submit run for counterfactual examples\n",
    "\n",
    "Generate counterfactuals for all the samples in the `test_dataset` based on the model analysis.\n",
    "The counterfactual run is a child run of the model analysis run.\n",
    "You may use the `add_request` method that allows you to specify extra parameters to configure the counterfactual examples to be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3651ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_config = CounterfactualConfig(model_analysis_run, run_config)\n",
    "cf_config.add_request(total_CFs=10, desired_range=[10, 300], feature_importance=True)\n",
    "cf_run = model_analysis_run.submit_child(cf_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d677ca",
   "metadata": {},
   "source": [
    "### Submit run for causal effects\n",
    "\n",
    "Compute causal effects based on the model analysis.\n",
    "The causal run is a child run of the model analysis run.\n",
    "You may use the `add_request` method that allows you to specify extra parameters to configure the causal effects to be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc985ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_config = CausalConfig(model_analysis_run, run_config)\n",
    "causal_config.add_request(\n",
    "    treatment_features=['ZN', 'NOX'],\n",
    "    nuisance_model='linear',\n",
    "    skip_cat_limit_checks=True)\n",
    "causal_run = model_analysis_run.submit_child(causal_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724fe62",
   "metadata": {},
   "source": [
    "## Download and inspect RAI insights\n",
    "In this section, we will demonstrate how to download the RAI insights computed in previous section and look at different aspects of your trained model.\n",
    "\n",
    "### Download explanations and view global feature importance\n",
    "Before downloading the explanations, make sure that the `explain_run` has completed.\n",
    "\n",
    "The `explanation_manager.list` method below returns a list of metadata dictionaries for each explain run.  In this case, there is a single explain run.  So, the list contains a single dictionary. \n",
    "\n",
    "You can then download the computed explanations using the `download_by_id` method in the `explanation_manager` and look at the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_run.wait_for_completion(raise_on_error=True, wait_post_processing=True)\n",
    "explanations_meta = model_analysis_run.explanation_manager.list()\n",
    "explanation = model_analysis_run.explanation_manager.download_by_id(explanations_meta[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca83bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.get_feature_importance_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098cbe1",
   "metadata": {},
   "source": [
    "### Download error analysis report\n",
    "Before downloading the error analysis report, make sure that the `error_analysis_run` has completed.\n",
    "\n",
    "The `error_analysis_manager.list` method below returns a list of metadata dictionaries for each error analysis run.  In this case, there is a single error analysis run.  So, the list contains a single dictionary. \n",
    "\n",
    "You can then download the computed error analysis report using the `download_by_id` method in the `error_analysis_manager` and inspect the error analysis report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443492de",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis_run.wait_for_completion(raise_on_error=True, wait_post_processing=True)\n",
    "erroranalysis_meta = model_analysis_run.error_analysis_manager.list()\n",
    "erroranalysis_report = model_analysis_run.error_analysis_manager.download_by_id(erroranalysis_meta[0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c7ed23",
   "metadata": {},
   "source": [
    "You can view the json tree and heatmap representations on the error analysis report directly, without the visualization widget or uploading it to AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18012f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "erroranalysis_report.tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7122056d",
   "metadata": {},
   "source": [
    "### Download counterfactuals examples\n",
    "Before downloading the counterfactual examples, make sure that the `cf_run` has completed.\n",
    "\n",
    "The `counterfactual_manager.list` method below returns a list of metadata dictionaries for each counterfactual run.  In this case, there is a single counterfactual run.  So, the list contains a single dictionary.\n",
    "\n",
    "The `download_by_id()` method available in the `counterfactual_manager` can be used to download the counterfactual example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f754b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_run.wait_for_completion(raise_on_error=True, wait_post_processing=True)\n",
    "cf_meta = model_analysis_run.counterfactual_manager.list()\n",
    "cf_meta\n",
    "counterfactual_object = model_analysis_run.counterfactual_manager.download_by_id(cf_meta[0]['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60782a",
   "metadata": {},
   "source": [
    "You can use `visualize_as_dataframe()` method to view the generated counterfactual examples for the samples in `test_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81421f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_object.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca87afcf",
   "metadata": {},
   "source": [
    "You can use `summary_importance` property to see the feature importance which is computed when generating counterfactual examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_object.summary_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485c110",
   "metadata": {},
   "source": [
    "### Download causal effects\n",
    "Before downloading the causal effects, make sure that the `causal_run` has completed.\n",
    "\n",
    "The `causal_manager.list` method below returns a list of metadata dictionaries for each causal effects run.  In this case, there is a single causal effects run.  So, the list contains a single dictionary. \n",
    "\n",
    "You can then download the computed causal effects using the `download_by_id` method in the `causal_manager` and inspect the downloaded causal effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5799efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_run.wait_for_completion(raise_on_error=True, wait_post_processing=True)\n",
    "causal_meta = model_analysis_run.causal_manager.list()\n",
    "causal_object = model_analysis_run.causal_manager.download_by_id(causal_meta[0]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824aff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_object['global_effects']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7f4478",
   "metadata": {},
   "source": [
    "# Responsible AI dashboard\n",
    "The dashboard containing the responsible AI insights, which were computed in previous sections, can be found under the Models section in [AzureML studio](https://ml.azure.com/)."
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "gaugup"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
